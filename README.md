# Knowledgeâ€‘Base Selfâ€‘Hosting Kit

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)


---

## ğŸ¯ What is this?

**Knowledgeâ€‘Base Selfâ€‘Hosting Kit** is a **complete, productionâ€‘ready starter template** that shows how to glue together the **Smartâ€‘Ingestâ€‘Kit** and **Smartâ€‘Routerâ€‘Kit** into a fullyâ€‘functional, selfâ€‘hosted knowledgeâ€‘base.

- ğŸ“„ **Docling**â€‘powered ingestion (PDF, DOCX, HTML, images, â€¦) with automatic chunking & metadata extraction.
- ğŸ§­ **Hybrid retrieval** (vector + keyword) + **parentâ€‘document reranker**.
- âš¡ï¸ Dockerâ€‘Compose setup that runs **ChromaDB**, **FastAPI**, and an optional **React** UI out of the box.
- ğŸ› ï¸ Ready for **local LLMs** via Ollama or any OpenAIâ€‘compatible endpoint.

The goal is to give developers a **single repository** that they can clone, run, and extend â€“ no piecing together of disparate tutorials required.

---

## ğŸš€ Quick Start (5â€¯minutes)

```bash
# 1ï¸âƒ£ Clone the repo
git clone https://github.com/2dogsandanerd/Knowledge-Base-Self-Hosting-Kit.git
cd Knowledge-Base-Self-Hosting-Kit

# 2ï¸âƒ£ (Optional) Set your LLM endpoint â€“ see the .env.example file
cp .env.example .env
# Edit .env if you want to use OpenAI, Ollama, etc.

# 3ï¸âƒ£ Build & run everything with Docker Compose
docker compose up -d --build

# 4ï¸âƒ£ Open the UI
open http://localhost:3000   # Web UI (or http://localhost:8080/docs for the API)
```

Thatâ€™s it â€“ the UI lets you **upload documents**, **run queries**, and **inspect the vector store**.

---

## ğŸ“¦ What's Inside?

```
.
â”œâ”€ backend/               # FastAPI server
â”‚   â”œâ”€ src/
â”‚   â”‚   â”œâ”€ api/v1/rag/   # RAG endpoints (ingestion, query, collections, documents)
â”‚   â”‚   â”œâ”€ core/          # Docling loader, ChromaDB manager, retrievers, postprocessors
â”‚   â”‚   â”œâ”€ services/      # Document loaders, ingestion pipeline, generators
â”‚   â”‚   â”œâ”€ config/        # Configuration management
â”‚   â”‚   â””â”€ utils/         # Utility functions
â”‚   â”œâ”€ requirements.txt   # Python dependencies
â”‚   â””â”€ Dockerfile
â”œâ”€ frontend/              # Simple web UI for document ingestion
â”‚   â””â”€ index.html
â”œâ”€ docker-compose.yml     # Orchestrates backend, worker, frontend, chromadb, redis
â”œâ”€ .env.example           # Example configuration
â””â”€ README.md               # You are reading it now!
```

---

## ğŸ› ï¸ Architecture Overview

1. **Ingestion Service** â€“ reads files, uses **Docling** to extract text, creates chunks, and stores embeddings in **ChromaDB**.
2. **Retrieval Pipeline** â€“ hybrid retrieval (vector + BM25) + **parentâ€‘document reranker** for relevance.
3. **API Layer** â€“ FastAPI exposing `/api/v1/rag/*` endpoints for ingestion, querying, and collection management.
4. **Task Queue** â€“ Celery workers for async ingestion with Redis as message broker.
5. **Frontend** â€“ Simple web UI for folder ingestion and progress tracking.
6. **LLM Provider** â€“ configurable via `.env` (Ollama, OpenAI, Anthropic, etc.).

---

## âš™ï¸ Configuration

| Variable | Description | Default |
|----------|-------------|---------|
| `LLM_PROVIDER` | `openai`, `ollama`, `anthropic` â€¦ | `ollama` |
| `LLM_MODEL` | Model name (e.g. `llama3.2:latest`) | `llama3.2:latest` |
| `CHROMA_HOST` | Host for ChromaDB | `chromadb` |
| `CHROMA_PORT` | Port for ChromaDB | `8000` |
| `INGEST_BATCH_SIZE` | Number of docs per batch | `10` |
| `EMBEDDING_MODEL` | Embedding model for Docling | `nomic-embed-text` |

Edit `.env` (or set environment variables) before starting the stack.

---

## ğŸ“š Documentation & Demo

- **Full docs** live in the `docs/` folder (Markdown + diagrams).
- **Demo video** â€“ see `docs/demo.mp4` (short 2â€‘minute walkthrough).
- **API reference** â€“ automatically generated Swagger UI at `http://localhost:8000/docs`.

---

## ğŸ¤ Contributing

We welcome contributions! Please read the **CONTRIBUTING.md** for:
- How to open a good issue.
- Coding style (black, isort, mypy).
- Running the test suite (`pytest -q`).
- Submitting a PR â€“ we use **GitHub Actions** to verify CI.

---

## ğŸ“œ License

MIT Â© 2025â€¯2dogsandanerd. See `LICENSE` for details.

---

## ğŸ™ Acknowledgements

- **Docling** â€“ for brilliant document parsing.
- **LlamaIndex** â€“ for the retrieval pipeline.
- **ChromaDB** â€“ for fast, persistent vector storage.
- The **r/docling** community for early feedback.

---

*If you liked this project, star it â˜… and share the link !*

---

## ğŸ¢ Editions

This repository contains the **Community Edition** - a fully functional RAG system for evaluation and learning.

### Community Edition (This Repository)
- âœ… Full RAG pipeline with ChromaDB
- âœ… Docling document processing
- âœ… Hybrid retrieval (vector + keyword)
- âœ… Basic ingestion pipeline
- âœ… Up to 3 collections, 1000 docs per collection
- âœ… Supports: PDF, TXT, Markdown
- âš ï¸  Basic heuristic-based features

### Professional Edition
**Advanced features for production deployments:**
- ğŸš€ 10 collections, 5000 docs per collection
- ğŸš€ Advanced reranking with cross-encoders
- ğŸš€ Multi-collection intelligent search
- ğŸš€ Extended format support (DOCX, HTML, PPTX, XLSX)
- ğŸš€ ML-powered document classification
- ğŸš€ Intelligent pattern generation
- ğŸš€ Team collaboration features

### Enterprise Edition
**Full-scale deployment with custom support:**
- ğŸ’¼ Unlimited collections and documents
- ğŸ’¼ Custom fine-tuned models
- ğŸ’¼ SSO and RBAC integration
- ğŸ’¼ Advanced analytics and monitoring
- ğŸ’¼ Dedicated support and SLA
- ğŸ’¼ Custom feature development
- ğŸ’¼ On-premise deployment assistance

**Interested in Professional or Enterprise?** Contact: [your-contact-email]

---

## ğŸ“ Note on Implementation

This Community Edition demonstrates our RAG architecture and provides functional basic features. Some components include references to advanced features available in paid editions:

- **Generators**: Basic implementations with notes on enterprise ML-powered versions
- **Classification**: Heuristic-based (Enterprise: ML models with confidence calibration)
- **Feature Limits**: Basic tier system (Enterprise: Dynamic licensing with usage tracking)

This approach allows you to:
- âœ… Evaluate the architecture and code quality
- âœ… Deploy a working RAG system immediately
- âœ… Understand what's possible with upgraded editions
- âœ… Make informed decisions about enterprise features

